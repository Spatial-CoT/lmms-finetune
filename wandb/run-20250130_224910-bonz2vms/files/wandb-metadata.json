{
  "os": "Linux-6.8.0-51-generic-x86_64-with-glibc2.39",
  "python": "CPython 3.10.16",
  "startedAt": "2025-01-30T22:49:10.439335Z",
  "args": [
    "--model_id",
    "llava-next-video-7b",
    "--data_path",
    "/home/rilyn/project-files/test/vsi-ft-dataset/data/qa_pairs/all_qa/fixed_dataset_20_percent.json",
    "--num_frames",
    "8",
    "--output_dir",
    "/home/rilyn/project-files/01-pj-moog/moog-pipeline-ft/fine-tuning/ckpt3/llava-next-video-7b_lora-True_qlora-False",
    "--report_to",
    "wandb",
    "--run_name",
    "llava-next-video-7b_lora-True_qlora-False",
    "--deepspeed",
    "./ds_configs/zero3.json",
    "--bf16",
    "True",
    "--num_train_epochs",
    "5",
    "--per_device_train_batch_size",
    "2",
    "--per_device_eval_batch_size",
    "2",
    "--gradient_accumulation_steps",
    "1",
    "--eval_strategy",
    "epoch",
    "--save_strategy",
    "epoch",
    "--save_total_limit",
    "1",
    "--learning_rate",
    "2e-5",
    "--weight_decay",
    "0.",
    "--warmup_ratio",
    "0.03",
    "--lr_scheduler_type",
    "cosine",
    "--logging_steps",
    "1",
    "--tf32",
    "True",
    "--model_max_length",
    "512",
    "--gradient_checkpointing",
    "True",
    "--dataloader_num_workers",
    "4",
    "--train_vision_encoder",
    "False",
    "--use_vision_lora",
    "False",
    "--train_vision_projector",
    "False",
    "--use_lora",
    "True",
    "--q_lora",
    "False",
    "--lora_r",
    "8",
    "--lora_alpha",
    "8"
  ],
  "program": "/home/rilyn/project-files/01-pj-moog/moog-pipeline-ft/lmms-finetune/train.py",
  "codePath": "train.py",
  "git": {
    "remote": "https://github.com/zjysteven/lmms-finetune.git",
    "commit": "1a4c6851fd82316a7d4485c5a513fc0f2a45def9"
  },
  "email": "rilyn.han@yale.edu",
  "root": "/home/rilyn/project-files/01-pj-moog/moog-pipeline-ft/lmms-finetune",
  "host": "opa-1",
  "executable": "/home/rilyn/anaconda3/envs/lmms-finetune/bin/python",
  "codePathLocal": "train.py",
  "cpu_count": 64,
  "cpu_count_logical": 128,
  "gpu": "NVIDIA A100-SXM4-80GB",
  "gpu_count": 4,
  "disk": {
    "/": {
      "total": "1887976378368",
      "used": "1554753179648"
    }
  },
  "memory": {
    "total": "1082008104960"
  },
  "cpu": {
    "count": 64,
    "countLogical": 128
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    }
  ],
  "cudaVersion": "12.6"
}